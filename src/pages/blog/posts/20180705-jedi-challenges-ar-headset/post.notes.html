<h3>Hacking something together</h3>
<h4>Step #1. Testing the dark background theory</h4>
<div>
    <img src="/assets/img/blog/lenovo-ar-headset/step-1-template.jpg" />
    <app-caption content="Getting the template up and running"></app-caption>
</div>
<p>The first step was to check whether my hypothesis was actually correct. I took a screenshot from the game, and then built a HTML page around it. As you can see in the image above, only a small part of the screen is actually used for the game. I took a simple environment with planets that I often use for demonstrations, changed the canvas element so that the AFrame scene is placed on the same spot as the game, and put it on the headset.</p>
<p>While it didn't look correct(the screen would need to be split), I was pretty ecstatic to see that, if I'd close one eye, I could see the planets being projected in my office. This could work. With a bit of additional hacking, I would be able to build projects with the headset.</p>

<h4>Step #2. The Stereo Effect</h4>
<p>Just like how every VR application renders the scene twice, once for each eye, I would have to do the same thing for this project. Initially, I wasn't able to figure out how to get this properly working in AFrame. The only time a Stereo Effect is used is when the user goes in Cardboard mode, which is a part from the WebVR polyfill, I think. Correct me if I'm wrong here. I would need to find a way to replicate this.</p>
<p>There are numerous tutorials on how to get a stereo effect working in Three.js(which AFrame uses). It took me some time to figure out how to really get this working. I would need to find a way to apply this effect as a postprocessing effect. Now, I don't believe it was documented at the time, but after looking through the AFrame script, I found a reference to a so-called 'tock' lifecycle method. With this method, I was able to properly apply the effect.</p>
<app-code-example [code]="stereoEffectExample" caption=""></app-code-example>
<p>Which results in...</p>
<div>
    <img src="/assets/img/blog/lenovo-ar-headset/step-2-stereo-effect.jpg" />
</div>
<p>Huzzah! We have a stereo effect. After trying it out in the AR Headset, I could now see the planets with both eyes. Next step was making use of the mobile's gyroscope to look around.</p>

<h4>Step #. The camera</h4>
<p>The next step was also a brainteaser. On a cardboard, you place the mobile horizontally in front of the lenses. In this case, you place the mobile in a holder and insert it vertically(with the display facing down) into the headset. As expected, the look-controls component from AFrame didn't work out of the box here.</p>
<p>The solution turned out to be very simple. I would have the camera facing down, and parent it to an entity that has the look-controls component attached to it. This way, the camera would properly move according to the headset's movement.</p>
<app-code-example [code]="cameraExample"></app-code-example>
